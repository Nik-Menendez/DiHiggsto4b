{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uproot\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import root_pandas\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Activation, Dense, Convolution2D, MaxPooling2D, Dropout, Flatten, LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('nn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sig  = '../analysis/objects_gg_HH_bbbb_SM.root'\n",
    "datsp_bkg  = '../background/data_3btag_with_weights_AR.root'\n",
    "input_dat  = '../analysis/objects_data_BTagCSV_Run2016_ALL.root'\n",
    "treename = 'bbbbTree'\n",
    "\n",
    "## convert to dataframes\n",
    "vars_training = [ 'H1_b1_pt', 'H1_b2_pt', 'H2_b1_pt', 'H2_b2_pt',\n",
    "#                  'H1_b1_m', 'H1_b2_m', 'H2_b1_m', 'H2_b2_m', \n",
    "                  'H1_b1_eta', 'H1_b2_eta', 'H2_b1_eta', 'H2_b2_eta', \n",
    "                  'H1_eta', 'H1_pt', 'H2_eta', 'H2_pt', \n",
    "                  'HH_eta', 'HH_pt','HH_m', 'H1H2_deltaEta', 'H1_costhetaCM', 'H1H2_deltaPhi']\n",
    "\n",
    "# extra variables needed for preselections\n",
    "all_vars = vars_training + ['H1_m', 'H2_m', 'n_btag', 'xs', 'norm_weight']\n",
    "all_vars = list(set(all_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file:  ../analysis/objects_gg_HH_bbbb_SM.root\n",
      "Opening file:  ../background/data_3btag_with_weights_AR.root\n",
      "Opening file:  ../analysis/objects_data_BTagCSV_Run2016_ALL.root\n",
      "Converting to pandas\n"
     ]
    }
   ],
   "source": [
    "# Save Scores in Dataframes\n",
    "\n",
    "print 'Opening file: ', input_sig\n",
    "arrs_sig  = uproot.open(input_sig)[treename]\n",
    "print 'Opening file: ', datsp_bkg\n",
    "arrs_bkg  = uproot.open(datsp_bkg)[treename]\n",
    "print 'Opening file: ', input_dat\n",
    "arrs_dat  = uproot.open(input_dat)[treename]\n",
    "\n",
    "print 'Converting to pandas'\n",
    "data_sig = arrs_sig.pandas.df(all_vars)\n",
    "data_bkg = arrs_bkg.pandas.df(all_vars+['bkg_model_w'])\n",
    "data_rel = arrs_dat.pandas.df(all_vars)\n",
    "\n",
    "## apply a selection on the datasets\n",
    "data_bkg = data_bkg[data_bkg['n_btag'] == 3]\n",
    "data_sig = data_sig[data_sig['n_btag'] >= 4]\n",
    "\n",
    "# restrict training to the signal region\n",
    "data_bkg['chi'] = np.sqrt( (data_bkg['H1_m']-120)*(data_bkg['H1_m']-120)+(data_bkg['H2_m']-110)*(data_bkg['H2_m']-110))\n",
    "data_sig['chi'] = np.sqrt( (data_sig['H1_m']-120)*(data_sig['H1_m']-120)+(data_sig['H2_m']-110)*(data_sig['H2_m']-110))\n",
    "data_rel['chi'] = np.sqrt( (data_rel['H1_m']-120)*(data_rel['H1_m']-120)+(data_rel['H2_m']-110)*(data_rel['H2_m']-110))\n",
    "\n",
    "data_bkg = data_bkg[data_bkg['chi'] < 30]\n",
    "data_sig = data_sig[data_sig['chi'] < 30]\n",
    "data_rel = data_rel[data_rel['chi'] < 30]\n",
    "\n",
    "data_bkg = data_bkg.drop(columns=['chi'])\n",
    "data_sig = data_sig.drop(columns=['chi'])\n",
    "data_rel = data_rel.drop(columns=['chi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label datasets\n",
      "Combine datasets\n"
     ]
    }
   ],
   "source": [
    "print 'Label datasets'\n",
    "data_bkg['isSignal'] = np.zeros(len(data_bkg))\n",
    "data_sig['isSignal'] = np.ones(len(data_sig))\n",
    "data_rel['isSignal'] = np.full(len(data_rel),2)\n",
    "\n",
    "print 'Combine datasets'\n",
    "all_data = pd.concat([data_bkg, data_sig, data_rel], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing input for NN\n"
     ]
    }
   ],
   "source": [
    "print 'Normalizing input for NN'\n",
    "scaler = StandardScaler().fit(all_data[vars_training])\n",
    "all_data[vars_training] = scaler.transform(all_data[vars_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting signal\n"
     ]
    }
   ],
   "source": [
    "print 'Predicting signal'\n",
    "all_data['BDT_Score'] = model.predict(all_data[vars_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnormalizing dataframe\n"
     ]
    }
   ],
   "source": [
    "print 'Unnormalizing dataframe'\n",
    "all_data[vars_training] = scaler.inverse_transform(all_data[vars_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating signal and background dataframes\n"
     ]
    }
   ],
   "source": [
    "print 'Separating signal and background dataframes'\n",
    "sig = all_data[all_data.isSignal == 1][all_vars+['BDT_Score']]\n",
    "bkg = all_data[all_data.isSignal == 0][all_vars+['BDT_Score', 'bkg_model_w']]\n",
    "rel = all_data[all_data.isSignal == 2][all_vars+['BDT_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write to root file\n"
     ]
    }
   ],
   "source": [
    "print 'Write to root file'\n",
    "sig.to_root('NN_signal.root',key='bbbbTree')\n",
    "bkg.to_root('NN_background.root',key='bbbbTree')\n",
    "rel.to_root('NN_data.root',key='bbbbTree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
